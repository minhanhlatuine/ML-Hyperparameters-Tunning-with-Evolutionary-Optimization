# ML-Hyperparameters-Tunning-with-Evolutionary-Optimization
We developed a program to automate hyperparameter optimization for two datasets, focusing on binary and multiple classification tasks. Our objectives included identifying the most suitable classification algorithms, achieving effective hyperparameter tuning, and enhancing prediction accuracy in practical applications.

Model evaluation is conducted on 4 models which are Support Vector Machine, Decision Tree, K-Nearest Neighbors, and Gradient Boosting, in order to find the best 2 models for further tuning with DEAP for both datasets (Census Income, and Glass Identification). This evaluation will cover the accuracy as well as fitness for the given data sets and Confusion matrix. Both datasets will be splitted into training and testing datasets with the ratio of 80, and 20  espectively. The accuracy of each model will be evaluated with 10-fold cross-validation. Furthermore, Receiver Operating Characteristic (ROC) curve and Area  nder Chart (AUC) coefficient visualize the performance of the model in terms of trends and benchmarks. Also, the default setting by sk-learn library will be considered as baseline performance of the Machine Learning model against each dataset.

We deploy the DEAP library to generate hyperparameter values of 2 selected Machine Learning algorithms using ‘toolbox.register’ in a specified range for both Census Income and Glass Identification Dataset. The genetic operators are used to modify individuals (solutions) in the population during the evolutionary process.The EA generic operators, parameter setups, and the pre-defined hyperparameter for each Machine Learning algorithm are described in the report (Section 3.4).
